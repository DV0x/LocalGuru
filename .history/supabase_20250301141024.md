Here's a comprehensive, step-by-step implementation plan for building Localguru from scratch through to a complete RAG system:

## Phase 1: Project Setup and Infrastructure

### Step 1: Set Up Next.js Project
```bash
# Create a new Next.js project
npx create-next-app@latest localguru --typescript
cd localguru

# Install necessary dependencies
npm install @supabase/supabase-js openai axios dotenv
npm install -D typescript @types/node ts-node
```

### Step 2: Create Environment Configuration
Create a `.env.local` file:
```
# Supabase credentials
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Reddit API credentials
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USERNAME=your_reddit_username
REDDIT_PASSWORD=your_reddit_password

# OpenAI API key for embeddings and completion
OPENAI_API_KEY=your_openai_api_key
```

### Step 3: Set Up Supabase Project
1. Create a new project in [Supabase Dashboard](https://app.supabase.com/)
2. Note your project URL and API keys for the `.env.local` file
3. Install Supabase CLI (for migrations):
```bash
npm install -g supabase
supabase login
```

### Step 4: Create Database Migrations
Create a `supabase/migrations` directory and add a migration file:

```sql
-- 20240301130000_initial_schema.sql

-- Enable vector extension
create extension if not exists vector;

-- Create table for Reddit posts
create table if not exists reddit_posts (
  id serial primary key,
  reddit_id text unique not null,
  title text not null,
  selftext text not null,
  subreddit text not null,
  permalink text not null,
  author text not null,
  created_utc timestamp not null,
  score integer not null,
  num_comments integer not null,
  upvote_ratio float not null,
  is_original_content boolean,
  link_flair_text text,
  url text,
  awards jsonb,
  extracted_locations text[],
  travel_type text,
  created_at timestamp with time zone default now()
);

-- Create table for post embeddings
create table if not exists post_embeddings (
  id serial primary key,
  post_id integer references reddit_posts(id) on delete cascade,
  embedding vector(1536) not null,
  created_at timestamp with time zone default now()
);

-- Create table for post comments (optional but valuable)
create table if not exists post_comments (
  id serial primary key,
  post_id integer references reddit_posts(id) on delete cascade,
  comment_id text unique not null,
  author text not null,
  body text not null,
  score integer not null,
  created_utc timestamp not null,
  created_at timestamp with time zone default now()
);

-- Create table for query cache
create table if not exists query_cache (
  id serial primary key,
  query text not null,
  response jsonb not null,
  created_at timestamp with time zone default now()
);

-- Create index for vector similarity search
create index on post_embeddings using ivfflat (embedding vector_cosine_ops) with (lists = 100);

-- Create similarity search function
create or replace function match_reddit_posts(
  query_embedding vector(1536),
  similarity_threshold float,
  match_count int
)
returns table (
  id bigint,
  post_id bigint,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    post_embeddings.id,
    post_embeddings.post_id,
    1 - (post_embeddings.embedding <=> query_embedding) as similarity
  from post_embeddings
  where 1 - (post_embeddings.embedding <=> query_embedding) > similarity_threshold
  order by similarity desc
  limit match_count;
end;
$$;
```

### Step 5: Apply Database Migrations
```bash
# Link to your Supabase project
supabase link --project-ref your-project-ref

# Apply migrations
supabase db push
```

## Phase 2: Core Services Implementation

### Step 6: Create TypeScript Type Definitions
Create a file `types/index.ts`:

```typescript
// types/index.ts
export interface RedditPost {
  id: number;
  reddit_id: string;
  title: string;
  selftext: string;
  subreddit: string;
  permalink: string;
  author: string;
  created_utc: Date;
  score: number;
  num_comments: number;
  upvote_ratio: number;
  is_original_content?: boolean;
  link_flair_text?: string;
  url?: string;
  awards?: any[];
  extracted_locations?: string[];
  travel_type?: string;
}

export interface RedditComment {
  id: number;
  post_id: number;
  comment_id: string;
  author: string;
  body: string;
  score: number;
  created_utc: Date;
}

export interface SearchResult extends RedditPost {
  similarity: number;
}

export interface RAGResponse {
  answer: string;
  sources: {
    title: string;
    subreddit: string;
    url: string;
    similarity: number;
  }[];
}
```

### Step 7: Create Supabase Client
Create a file `lib/supabase.ts`:

```typescript
// lib/supabase.ts
import { createClient } from '@supabase/supabase-js';
import { Database } from '../types/database'; // This will be generated later

// Check environment variables
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseAnonKey) {
  throw new Error('Missing Supabase environment variables');
}

// Create client for public access
export const supabase = createClient<Database>(
  supabaseUrl, 
  supabaseAnonKey
);

// Create admin client for server-side operations
export const supabaseAdmin = supabaseServiceKey 
  ? createClient<Database>(supabaseUrl, supabaseServiceKey, {
      auth: { persistSession: false }
    })
  : supabase;
```

### Step 8: Implement Reddit API Service
Create a file `services/redditService.ts`:

```typescript
// services/redditService.ts
import axios from 'axios';
import { RedditPost } from '../types';

class RedditService {
  private accessToken: string | null = null;
  private tokenExpiry: number = 0;
  
  private async authenticate(): Promise<void> {
    const clientId = process.env.REDDIT_CLIENT_ID;
    const clientSecret = process.env.REDDIT_CLIENT_SECRET;
    const username = process.env.REDDIT_USERNAME;
    const password = process.env.REDDIT_PASSWORD;
    
    if (!clientId || !clientSecret || !username || !password) {
      throw new Error('Reddit API credentials not configured');
    }
    
    try {
      const response = await axios.post(
        'https://www.reddit.com/api/v1/access_token',
        `grant_type=password&username=${username}&password=${password}`,
        {
          headers: {
            'Content-Type': 'application/x-www-form-urlencoded',
            'User-Agent': 'Localguru/1.0.0'
          },
          auth: {
            username: clientId,
            password: clientSecret
          }
        }
      );
      
      this.accessToken = response.data.access_token;
      this.tokenExpiry = Date.now() + (response.data.expires_in * 1000);
      console.log('Reddit authentication successful');
      
    } catch (error) {
      console.error('Reddit authentication failed:', error);
      throw new Error('Failed to authenticate with Reddit API');
    }
  }
  
  private async ensureAuthenticated(): Promise<void> {
    if (!this.accessToken || Date.now() >= this.tokenExpiry - 60000) {
      await this.authenticate();
    }
  }
  
  async fetchSubredditPosts(subreddit: string, limit: number = 100, after?: string): Promise<{
    posts: Partial<RedditPost>[];
    after: string | null;
  }> {
    await this.ensureAuthenticated();
    
    try {
      let url = `https://oauth.reddit.com/r/${subreddit}/top.json?limit=${limit}&t=year&raw_json=1`;
      if (after) {
        url += `&after=${after}`;
      }
      
      const response = await axios.get(url, {
        headers: {
          Authorization: `Bearer ${this.accessToken}`,
          'User-Agent': 'Localguru/1.0.0'
        }
      });
      
      return {
        posts: response.data.data.children.map((child: any) => ({
          reddit_id: child.data.id,
          title: child.data.title,
          selftext: child.data.selftext,
          subreddit: child.data.subreddit,
          permalink: child.data.permalink,
          author: child.data.author,
          created_utc: new Date(child.data.created_utc * 1000),
          score: child.data.score,
          num_comments: child.data.num_comments,
          upvote_ratio: child.data.upvote_ratio,
          is_original_content: child.data.is_original_content,
          link_flair_text: child.data.link_flair_text,
          url: child.data.url,
          awards: this.processAwards(child.data.all_awardings)
        })),
        after: response.data.data.after
      };
    } catch (error) {
      console.error(`Error fetching posts from r/${subreddit}:`, error);
      throw new Error(`Failed to fetch posts from r/${subreddit}`);
    }
  }
  
  async fetchPostComments(postId: string, subreddit: string): Promise<any[]> {
    await this.ensureAuthenticated();
    
    try {
      const response = await axios.get(
        `https://oauth.reddit.com/r/${subreddit}/comments/${postId}.json?raw_json=1`,
        {
          headers: {
            Authorization: `Bearer ${this.accessToken}`,
            'User-Agent': 'Localguru/1.0.0'
          }
        }
      );
      
      // Extract comments from the nested structure
      return response.data[1].data.children
        .filter((child: any) => child.kind === 't1')
        .map((child: any) => ({
          comment_id: child.data.id,
          author: child.data.author,
          body: child.data.body,
          score: child.data.score,
          created_utc: new Date(child.data.created_utc * 1000)
        }));
    } catch (error) {
      console.error(`Error fetching comments for post ${postId}:`, error);
      throw new Error(`Failed to fetch comments for post ${postId}`);
    }
  }
  
  private processAwards(awards: any[]): any {
    if (!awards || !Array.isArray(awards)) return [];
    return awards.map(award => ({
      name: award.name,
      count: award.count,
      description: award.description
    }));
  }
}

export const redditService = new RedditService();
```

### Step 9: Implement Embedding Service
Create a file `services/embeddingService.ts`:

```typescript
// services/embeddingService.ts
import OpenAI from 'openai';
import { supabaseAdmin } from '../lib/supabase';
import { SearchResult } from '../types';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export class EmbeddingService {
  async generateEmbedding(text: string): Promise<number[]> {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OpenAI API key not configured');
    }
    
    try {
      const response = await openai.embeddings.create({
        model: "text-embedding-3-small",
        input: text,
      });
      
      return response.data[0].embedding;
    } catch (error) {
      console.error('Error generating embedding:', error);
      throw new Error('Failed to generate embedding');
    }
  }
  
  prepareTextForEmbedding(title: string, selftext: string): string {
    // Combine title and text with proper formatting
    // Limit size to avoid token limits
    return `Title: ${title}\n\nContent: ${selftext}`.slice(0, 8000);
  }
  
  async storeEmbedding(postId: number, embedding: number[]): Promise<void> {
    try {
      const { error } = await supabaseAdmin
        .from('post_embeddings')
        .insert({
          post_id: postId,
          embedding
        });
        
      if (error) throw error;
    } catch (error) {
      console.error('Error storing embedding:', error);
      throw new Error('Failed to store embedding');
    }
  }
  
  async semanticSearch(query: string, threshold = 0.7, limit = 5): Promise<SearchResult[]> {
    try {
      // Generate embedding for query
      const embedding = await this.generateEmbedding(query);
      
      // Use database function to find similar posts
      const { data: matches, error } = await supabaseAdmin.rpc(
        'match_reddit_posts',
        {
          query_embedding: embedding,
          similarity_threshold: threshold,
          match_count: limit
        }
      );
      
      if (error) throw error;
      
      if (!matches || matches.length === 0) {
        return [];
      }
      
      // Get the actual post details
      const postIds = matches.map(match => match.post_id);
      
      const { data: posts, error: postsError } = await supabaseAdmin
        .from('reddit_posts')
        .select('*')
        .in('id', postIds);
        
      if (postsError) throw postsError;
      
      // Map similarity scores to posts
      return posts.map(post => {
        const match = matches.find(m => m.post_id === post.id);
        return {
          ...post,
          similarity: match ? match.similarity : 0
        };
      }).sort((a, b) => b.similarity - a.similarity);
    } catch (error) {
      console.error('Error performing semantic search:', error);
      throw new Error('Failed to perform semantic search');
    }
  }
}

export const embeddingService = new EmbeddingService();
```

### Step 10: Implement RAG Service
Create a file `services/ragService.ts`:

```typescript
// services/ragService.ts
import OpenAI from 'openai';
import { embeddingService } from './embeddingService';
import { RAGResponse } from '../types';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export class RAGService {
  async generateResponse(query: string): Promise<RAGResponse> {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OpenAI API key not configured');
    }
    
    // 1. Retrieve relevant documents
    const relevantPosts = await embeddingService.semanticSearch(query, 0.7, 5);
    
    if (relevantPosts.length === 0) {
      return {
        answer: "I couldn't find any relevant travel recommendations for your query. Please try a different question or be more specific about your travel interests.",
        sources: []
      };
    }
    
    // 2. Format context from retrieved documents
    const contextText = relevantPosts
      .map(post => `
TITLE: ${post.title}
SUBREDDIT: r/${post.subreddit}
CONTENT: ${post.selftext.slice(0, 1000)}${post.selftext.length > 1000 ? '...' : ''}
SCORE: ${post.score} | COMMENTS: ${post.num_comments}
---
      `)
      .join('\n');
    
    // 3. Create the prompt with retrieved context
    const prompt = `
You are Localguru, a travel recommendation assistant based on real experiences shared by travelers.
Answer the following question based ONLY on the provided Reddit posts.
If the provided information doesn't contain a relevant answer, acknowledge this limitation and suggest the user try a more specific query.
Don't make up information not present in the sources.

QUESTION: ${query}

RELEVANT REDDIT POSTS:
${contextText}

Provide a helpful, conversational response that directly answers the user's query.
Include specific travel recommendations with details from the sources, such as places to visit, activities, local tips, or other relevant advice.
Highlight key information that would be most helpful to a traveler.
At the end, cite which Reddit posts you used as sources by their titles.
`;
    
    // 4. Generate response using augmented context
    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-4-turbo",
        messages: [
          { role: "system", content: "You are Localguru, a helpful travel assistant providing recommendations based on real traveler experiences from Reddit." },
          { role: "user", content: prompt }
        ],
        temperature: 0.7,
        max_tokens: 1000,
      });
      
      // 5. Format sources for citation
      const sources = relevantPosts.map(post => ({
        title: post.title,
        subreddit: post.subreddit,
        url: `https://reddit.com${post.permalink}`,
        similarity: post.similarity
      }));
      
      return {
        answer: completion.choices[0].message.content || "I couldn't generate a response",
        sources
      };
    } catch (error) {
      console.error('Error generating RAG response:', error);
      throw new Error('Failed to generate travel recommendations');
    }
  }
}

export const ragService = new RAGService();
```

## Phase 3: Data Collection and Processing

### Step 11: Create Data Collection Script
Create a file `scripts/collectRedditData.ts`:

```typescript
// scripts/collectRedditData.ts
import { redditService } from '../services/redditService';
import { embeddingService } from '../services/embeddingService';
import { supabaseAdmin } from '../lib/supabase';

// Configure travel subreddits to scrape
const TRAVEL_SUBREDDITS = [
  'travel',
  'solotravel',
  'backpacking',
  'roadtrip',
  'TravelHacks',
  'shoestring',
  'digitalnomad',
  'Cruise',
  'travelphotos',
  'travelpartners'
];

// Basic location extraction (to be improved with NER model)
function extractLocations(text: string): string[] {
  const commonLocations = [
    'Paris', 'London', 'Tokyo', 'New York', 'Bangkok', 'Rome', 'Barcelona',
    'Amsterdam', 'Istanbul', 'Dubai', 'Singapore', 'Hong Kong', 'Sydney',
    'France', 'Italy', 'Japan', 'Thailand', 'Spain', 'Netherlands', 'Turkey',
    'USA', 'UK', 'Europe', 'Asia', 'North America', 'South America'
  ];
  
  const foundLocations = [];
  for (const location of commonLocations) {
    if (text.toLowerCase().includes(location.toLowerCase())) {
      foundLocations.push(location);
    }
  }
  
  return foundLocations;
}

// Simple travel type classification
function classifyTravelType(text: string): string | null {
  const keywords = {
    'solo': ['solo', 'alone', 'myself', 'single'],
    'family': ['family', 'kids', 'children', 'parent'],
    'couple': ['couple', 'honeymoon', 'romantic', 'anniversary'],
    'budget': ['budget', 'cheap', 'affordable', 'shoestring'],
    'luxury': ['luxury', 'high-end', 'expensive', 'premium']
  };
  
  const textLower = text.toLowerCase();
  
  for (const [type, words] of Object.entries(keywords)) {
    for (const word of words) {
      if (textLower.includes(word)) {
        return type;
      }
    }
  }
  
  return null;
}

async function collectRedditData() {
  console.log('Starting Reddit data collection...');
  
  for (const subreddit of TRAVEL_SUBREDDITS) {
    console.log(`Processing r/${subreddit}...`);
    let after: string | null = null;
    let totalProcessed = 0;
    
    do {
      try {
        // Fetch posts with pagination
        const result = await redditService.fetchSubredditPosts(subreddit, 100, after);
        after = result.after;
        
        // Filter posts with meaningful content
        const validPosts = result.posts.filter(post => 
          post.selftext && post.selftext.length > 100 && post.score > 5
        );
        
        console.log(`Found ${validPosts.length} valid posts from r/${subreddit}`);
        
        // Process each post
        for (const post of validPosts) {
          // Extract locations and travel type
          const combinedText = `${post.title} ${post.selftext}`;
          const extractedLocations = extractLocations(combinedText);
          const travelType = classifyTravelType(combinedText);
          
          // Add derived fields
          const enhancedPost = {
            ...post,
            extracted_locations: extractedLocations,
            travel_type: travelType
          };
          
          // Insert post into database
          const { data: insertedPost, error } = await supabaseAdmin
            .from('reddit_posts')
            .insert(enhancedPost)
            .select('id')
            .single();
            
          // Skip duplicates but log them
          if (error) {
            if (error.code === '23505') {
              console.log(`Skipping duplicate post: ${post.reddit_id}`);
              continue;
            }
            throw error;
          }
          
          // Generate and store embedding
          const textForEmbedding = embeddingService.prepareTextForEmbedding(
            post.title || '', 
            post.selftext || ''
          );
          const embedding = await embeddingService.generateEmbedding(textForEmbedding);
          await embeddingService.storeEmbedding(insertedPost.id, embedding);
          
          // Fetch and store comments (optional)
          try {
            const comments = await redditService.fetchPostComments(post.reddit_id, post.subreddit);
            
            // Store top comments (up to 10)
            const topComments = comments
              .sort((a, b) => b.score - a.score)
              .slice(0, 10);
              
            if (topComments.length > 0) {
              for (const comment of topComments) {
                await supabaseAdmin
                  .from('post_comments')
                  .insert({
                    post_id: insertedPost.id,
                    ...comment
                  });
              }
              console.log(`Stored ${topComments.length} comments for post ${post.reddit_id}`);
            }
          } catch (commentError) {
            console.error(`Error fetching comments for post ${post.reddit_id}:`, commentError);
            // Continue with next post even if comment fetching fails
          }
          
          totalProcessed++;
          console.log(`Processed post "${post.title?.substring(0, 30)}..." (${totalProcessed} total)`);
          
          // Respect rate limits
          await new Promise(resolve => setTimeout(resolve, 1000)); 
        }
        
        console.log(`Completed batch from r/${subreddit}, processed ${totalProcessed} posts so far`);
        
        // If no more pages, break
        if (!after) break;
        
        // Add delay between pages to respect rate limits
        await new Promise(resolve => setTimeout(resolve, 2000));
        
      } catch (error) {
        console.error(`Error processing r/${subreddit}:`, error);
        // Wait longer if we hit rate limits
        await new Promise(resolve => setTimeout(resolve, 30000));
      }
    } while (after && totalProcessed < 500); // Limit to 500 posts per subreddit
  }
  
  console.log('Data collection complete!');
}

// Run the script
collectRedditData().catch(console.error);
```

### Step 12: Create Test Script
Create a file `scripts/testVectorSearch.ts`:

```typescript
// scripts/testVectorSearch.ts
import { embeddingService } from '../services/embeddingService';

async function testVectorSearch() {
  const testQueries = [
    "Best budget-friendly places to visit in Europe",
    "Hidden gems in Southeast Asia for solo travelers",
    "Safest countries for women traveling alone",
    "Family-friendly beach destinations in the Mediterranean",
    "Most scenic road trips in the United States"
  ];
  
  console.log("Testing vector search functionality...\n");
  
  for (const query of testQueries) {
    console.log(`Query: "${query}"`);
    
    try {
      console.time('Search time');
      const results = await embeddingService.semanticSearch(query, 0.6, 3);
      console.timeEnd('Search time');
      
      console.log(`Found ${results.length} results\n`);
      
      for (const [index, result] of results.entries()) {
        console.log(`Result ${index + 1} (Similarity: ${(result.similarity * 100).toFixed(2)}%)`);
        console.log(`Title: ${result.title}`);
        console.log(`Subreddit: r/${result.subreddit}`);
        console.log(`Score: ${result.score} | Comments: ${result.num_comments}`);
        console.log(`URL: https://reddit.com${result.permalink}`);
        console.log(`Locations: ${result.extracted_locations?.join(', ') || 'None detected'}`);
        console.log('-'.repeat(80) + '\n');
      }
    } catch (error) {
      console.error(`Error testing query "${query}":`, error);
    }
  }
}

testVectorSearch().catch(console.error);
```

### Step 13: Create RAG Test Script
Create a file `scripts/testRag.ts`:

```typescript
// scripts/testRag.ts
import { ragService } from '../services/ragService';

async function testRag() {
  const testQueries = [
    "What are the best places to visit in Japan for first-time visitors?",
    "I'm planning a budget backpacking trip around Europe. Where should I go?",
    "Best food experiences in Thailand?",
    "Is it safe to travel alone in South America as a woman?",
    "Hidden gems in Italy that tourists usually miss?"
  ];
  
  console.log("Testing RAG functionality...\n");
  
  for (const query of testQueries) {
    console.log(`Query: "${query}"`);
    
    try {
      console.time('RAG response time');
      const response = await ragService.generateResponse(query);
      console.timeEnd('RAG response time');
      
      console.log("\nGenerated Answer:");
      console.log("-".repeat(80));
      console.log(response.answer);
      console.log("-".repeat(80));
      
      console.log("\nSources:");
      for (const [index, source] of response.sources.entries()) {
        console.log(`${index + 1}. ${source.title} (r/${source.subreddit}) - ${Math.round(source.similarity * 100)}% match`);
      }
      
      console.log("\n" + "=".repeat(80) + "\n");
    } catch (error) {
      console.error(`Error testing RAG for query "${query}":`, error);
    }
  }
}

testRag().catch(console.error);
```

## Phase 4: API Implementation

### Step 14: Add Vector Search API Endpoint
Create a file `pages/api/search.ts`:

```typescript
// pages/api/search.ts
import type { NextApiRequest, NextApiResponse } from 'next';
import { embeddingService } from '../../services/embeddingService';
import { SearchResult } from '../../types';

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<{ results: SearchResult[] } | { error: string }>
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { query, threshold = 0.7, limit = 5 } = req.body;
  
  if (!query || typeof query !== 'string') {
    return res.status(400).json({ error: 'Valid query string is required' });
  }
  
  try {
    const results = await embeddingService.semanticSearch(
      query,
      parseFloat(threshold.toString()),
      parseInt(limit.toString())
    );
    
    return res.status(200).json({ results });
  } catch (error: any) {
    console.error('Search failed:', error);
    return res.status(500).json({ error: error.message || 'Search failed' });
  }
}
```

### Step 15: Add RAG API Endpoint
Create a file `pages/api/rag.ts`:

```typescript
// pages/api/rag.ts
import type { NextApiRequest, NextApiResponse } from 'next';
import { ragService } from '../../services/ragService';
import { RAGResponse } from '../../types';
import { supabaseAdmin } from '../../lib/supabase';

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<RAGResponse | { error: string }>
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { query } = req.body;
  
  if (!query || typeof query !== 'string') {
    return res.status(400).json({ error: 'Valid query string is required' });
  }
  
  try {
    // Check cache first
    const { data: cachedResponse } = await supabaseAdmin
      .from('query_cache')
      .select('response')
      .eq('query', query.toLowerCase().trim())
      .maybeSingle();
      
    // If we have a cached response, return it
    if (cachedResponse) {
      return res.status(200).json(cachedResponse.response as RAGResponse);
    }
    
    // Generate new response
    const response = await ragService.generateResponse(query);
    
    // Cache the response for future use
    await supabaseAdmin
      .from('query_cache')
      .insert({
        query: query.toLowerCase().trim(),
        response
      });
    
    return res.status(200).json(response);
  } catch (error: any) {
    console.error('RAG generation failed:', error);
    return res.status(500).json({ error: error.message || 'Failed to generate recommendations' });
  }
}
```

## Phase 5: Frontend Implementation with Server-Side Rendering

### Step 16: Setup App Router Structure

Replace the existing frontend structure with App Router:

```typescript
// app/layout.tsx
import type { Metadata } from 'next';
import { Inter } from 'next/font/google';
import './globals.css';

const inter = Inter({ subsets: ['latin'] });

export const metadata: Metadata = {
  title: 'Localguru - Smart Travel Recommendations',
  description: 'Find unique travel destinations and tips based on real traveler experiences',
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <div className="min-h-screen bg-gray-50">
          <header className="bg-white shadow-sm">
            <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-4">
              <h1 className="text-2xl font-bold text-blue-600">Localguru</h1>
              <p className="text-gray-500">Smart Travel Recommendations</p>
            </div>
          </header>
          <main className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
            {children}
          </main>
          <footer className="bg-white border-t mt-12 py-8">
            <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center text-gray-500">
              <p>Powered by real traveler experiences from Reddit</p>
            </div>
          </footer>
        </div>
      </body>
    </html>
  );
}
```

### Step 17: Create Home Page with Server Components

```typescript
// app/page.tsx
import { Suspense } from 'react';
import RAGSearchClient from '@/components/rag-search-client';
import StatsDisplay from '@/components/stats-display';
import LoadingSpinner from '@/components/ui/loading-spinner';

export default function Home() {
  return (
    <div className="space-y-8">
      <section className="text-center mb-12">
        <h2 className="text-3xl font-bold mb-4">Find Hidden Travel Gems</h2>
        <p className="text-lg text-gray-600 max-w-3xl mx-auto">
          Ask Localguru for personalized travel recommendations based on real experiences
          from travelers around the world.
        </p>
      </section>
      
      <RAGSearchClient />
      
      <section className="mt-12 pt-8 border-t border-gray-200">
        <h2 className="text-2xl font-semibold mb-6">Traveler Insights</h2>
        <Suspense fallback={<LoadingSpinner />}>
          <StatsDisplay />
        </Suspense>
      </section>
    </div>
  );
}
```

### Step 18: Implement Server Components for Data Fetching

```typescript
// components/stats-display.tsx
import { supabaseAdmin } from '@/lib/supabase';

// This is a Server Component - no 'use client' directive
export default async function StatsDisplay() {
  // Fetch statistics directly from the server
  const { data: postCount } = await supabaseAdmin
    .from('reddit_posts')
    .select('count', { count: 'exact', head: true });
    
  const { data: subreddits } = await supabaseAdmin
    .from('reddit_posts')
    .select('subreddit')
    .distinct();
    
  const { data: topLocations } = await supabaseAdmin
    .from('reddit_posts')
    .select('extracted_locations')
    .not('extracted_locations', 'is', null)
    .limit(100);
    
  // Process data to get top locations
  const locationCounts: Record<string, number> = {};
  topLocations?.forEach(post => {
    post.extracted_locations?.forEach(location => {
      locationCounts[location] = (locationCounts[location] || 0) + 1;
    });
  });
  
  const topLocationsList = Object.entries(locationCounts)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(([name, count]) => ({ name, count }));
  
  return (
    <div className="grid grid-cols-1 md:grid-cols-3 gap-6">
      <div className="bg-white p-6 rounded-lg shadow-sm">
        <h3 className="text-lg font-medium text-gray-900">Travel Content</h3>
        <p className="mt-2 text-3xl font-bold text-blue-600">{postCount?.count || 0}</p>
        <p className="text-sm text-gray-500">Reddit posts analyzed</p>
      </div>
      
      <div className="bg-white p-6 rounded-lg shadow-sm">
        <h3 className="text-lg font-medium text-gray-900">Travel Communities</h3>
        <p className="mt-2 text-3xl font-bold text-blue-600">{subreddits?.length || 0}</p>
        <p className="text-sm text-gray-500">Subreddits indexed</p>
      </div>
      
      <div className="bg-white p-6 rounded-lg shadow-sm">
        <h3 className="text-lg font-medium text-gray-900">Popular Destinations</h3>
        <ul className="mt-2 space-y-1">
          {topLocationsList.map(location => (
            <li key={location.name} className="flex justify-between">
              <span>{location.name}</span>
              <span className="text-gray-500">{location.count} mentions</span>
            </li>
          ))}
        </ul>
      </div>
    </div>
  );
}
```

### Step 19: Create Loading and Error States

```typitten
// app/loading.tsx
import LoadingSpinner from '@/components/ui/loading-spinner';

export default function Loading() {
  return (
    <div className="flex flex-col items-center justify-center min-h-[50vh]">
      <LoadingSpinner size="large" />
      <p className="mt-4 text-gray-600">Loading travel insights...</p>
    </div>
  );
}

// app/error.tsx
'use client';

import { useEffect } from 'react';
import Link from 'next/link';

export default function Error({
  error,
  reset,
}: {
  error: Error & { digest?: string };
  reset: () => void;
}) {
  useEffect(() => {
    // Log the error to an error reporting service
    console.error('Application error:', error);
  }, [error]);

  return (
    <div className="flex flex-col items-center justify-center min-h-[50vh] text-center">
      <h2 className="text-2xl font-bold text-red-600 mb-4">Something went wrong</h2>
      <p className="text-gray-600 mb-6">
        We encountered an error while loading your travel recommendations.
      </p>
      <div className="flex gap-4">
        <button
          onClick={reset}
          className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-colors"
        >
          Try again
        </button>
        <Link 
          href="/"
          className="px-4 py-2 bg-gray-200 text-gray-800 rounded-lg hover:bg-gray-300 transition-colors"
        >
          Go home
        </Link>
      </div>
    </div>
  );
}

// components/ui/loading-spinner.tsx
export default function LoadingSpinner({ size = 'medium' }: { size?: 'small' | 'medium' | 'large' }) {
  const sizeClasses = {
    small: 'w-4 h-4',
    medium: 'w-8 h-8',
    large: 'w-12 h-12'
  };
  
  return (
    <div className="flex justify-center">
      <div className={`${sizeClasses[size]} border-4 border-blue-200 border-t-blue-600 rounded-full animate-spin`}></div>
    </div>
  );
}
```

### Step 20: Convert RAG Search to Client Component with Proper Separation

```typescript
// components/rag-search-client.tsx
'use client';

import { useState, useRef } from 'react';
import { RAGResponse } from '@/types';
import SearchResults from './search-results';

export default function RAGSearchClient() {
  const [query, setQuery] = useState('');
  const [response, setResponse] = useState<RAGResponse | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isListening, setIsListening] = useState(false);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  const startListening = () => {
    if (typeof window !== 'undefined' && (window.SpeechRecognition || window.webkitSpeechRecognition)) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'en-US';
      
      recognitionRef.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setQuery(transcript);
        setIsListening(false);
      };
      
      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error', event.error);
        setError(`Error: ${event.error}. Please try again.`);
        setIsListening(false);
      };
      
      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
      
      recognitionRef.current.start();
    } else {
      setError('Speech recognition is not supported in your browser.');
    }
  };

  const stopListening = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  };

  const handleSearch = async (e: React.FormEvent) => {
    e.preventDefault();
    
    if (!query.trim()) return;
    
    setIsLoading(true);
    setError(null);
    
    try {
      const result = await fetch('/api/rag', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ query }),
      });
      
      if (!result.ok) {
        const errorData = await result.json();
        throw new Error(errorData.error || 'Failed to generate recommendations');
      }
      
      const data = await result.json();
      setResponse(data);
      
    } catch (err: any) {
      setError(err.message);
      console.error('RAG error:', err);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="w-full max-w-3xl mx-auto">
      <form onSubmit={handleSearch} className="mb-8">
        <div className="flex flex-col sm:flex-row gap-2">
          <input
            type="text"
            value={query}
            onChange={(e) => setQuery(e.target.value)}
            placeholder="Ask about travel recommendations..."
            className="flex-1 p-3 border rounded-lg shadow-sm"
          />
          <div className="flex gap-2">
            <button 
              type="button"
              onClick={isListening ? stopListening : startListening}
              className={`p-3 rounded-lg transition-colors ${
                isListening 
                  ? 'bg-red-100 text-red-600 animate-pulse' 
                  : 'bg-blue-100 text-blue-600 hover:bg-blue-200'
              }`}
              aria-label={isListening ? "Stop listening" : "Start voice input"}
            >
              {isListening ? (
                <span className="flex items-center">
                  <svg className="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clipRule="evenodd" />
                  </svg>
                  Recording...
                </span>
              ) : (
                <span className="flex items-center">
                  <svg className="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <path fillRule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clipRule="evenodd" />
                  </svg>
                  Voice Input
                </span>
              )}
            </button>
          </div>
        </div>
      </form>
      
      {error && (
        <div className="p-4 mb-4 text-red-700 bg-red-100 rounded-lg">
          {error}
        </div>
      )}
      
      {isLoading && <LoadingSpinner />}
      
      {response && <SearchResults response={response} />}
    </div>
  );
}
```

### Step 21: Create Individual Post Page with Dynamic Routing

```typescript
// app/post/[id]/page.tsx
import { notFound } from 'next/navigation';
import { supabaseAdmin } from '@/lib/supabase';
import Link from 'next/link';
import { formatDistanceToNow } from 'date-fns';

export async function generateMetadata({ params }: { params: { id: string } }) {
  const { data: post } = await supabaseAdmin
    .from('reddit_posts')
    .select('*')
    .eq('id', params.id)
    .single();
    
  if (!post) {
    return {
      title: 'Post Not Found - Localguru'
    };
  }
  
  return {
    title: `${post.title} - Localguru`,
    description: post.selftext.substring(0, 160)
  };
}

export default async function PostPage({ params }: { params: { id: string } }) {
  const { data: post, error } = await supabaseAdmin
    .from('reddit_posts')
    .select(`
      *,
      post_comments(*)
    `)
    .eq('id', params.id)
    .single();
    
  if (error || !post) {
    notFound();
  }
  
  return (
    <div className="max-w-4xl mx-auto">
      <Link href="/" className="text-blue-500 hover:underline mb-6 inline-block">
        ← Back to search
      </Link>
      
      <article className="bg-white rounded-lg shadow-sm p-6 mb-8">
        <header className="mb-6">
          <h1 className="text-2xl font-bold text-gray-900 mb-2">{post.title}</h1>
          <div className="flex items-center text-sm text-gray-500">
            <span>Posted by u/{post.author}</span>
            <span className="mx-2">•</span>
            <span>{formatDistanceToNow(new Date(post.created_utc))} ago</span>
            <span className="mx-2">•</span>
            <span>r/{post.subreddit}</span>
          </div>
        </header>
        
        <div className="prose max-w-none">
          {post.selftext.split('\n').map((paragraph, i) => (
            paragraph ? <p key={i} className="mb-4">{paragraph}</p> : <br key={i} />
          ))}
        </div>
        
        {post.extracted_locations && post.extracted_locations.length > 0 && (
          <div className="mt-6 pt-4 border-t border-gray-100">
            <h2 className="text-lg font-semibold mb-2">Mentioned Locations</h2>
            <div className="flex flex-wrap gap-2">
              {post.extracted_locations.map(location => (
                <span key={location} className="px-2 py-1 bg-blue-50 text-blue-700 rounded text-sm">
                  {location}
                </span>
              ))}
            </div>
          </div>
        )}
        
        <div className="mt-6 flex items-center text-sm text-gray-500">
          <span className="flex items-center">
            <svg className="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
              <path d="M2 10.5a1.5 1.5 0 113 0v6a1.5 1.5 0 01-3 0v-6zM6 10.333v5.43a2 2 0 001.106 1.79l.05.025A4 4 0 008.943 18h5.416a2 2 0 001.962-1.608l1.2-6A2 2 0 0015.56 8H12V4a2 2 0 00-2-2 1 1 0 00-1 1v.667a4 4 0 01-.8 2.4L6.8 7.933a4 4 0 00-.8 2.4z" />
            </svg>
            {post.score} upvotes
          </span>
          <span className="mx-4">•</span>
          <span className="flex items-center">
            <svg className="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
              <path fillRule="evenodd" d="M18 5v8a2 2 0 01-2 2h-5l-5 4v-4H4a2 2 0 01-2-2V5a2 2 0 012-2h12a2 2 0 012 2zM7 8H5v2h2V8zm2 0h2v2H9V8zm6 0h-2v2h2V8z" clipRule="evenodd" />
            </svg>
            {post.num_comments} comments
          </span>
        </div>
      </article>
      
      {post.post_comments && post.post_comments.length > 0 && (
        <section className="mt-8">
          <h2 className="text-xl font-semibold mb-4">Top Comments</h2>
          <div className="space-y-4">
            {post.post_comments.map(comment => (
              <div key={comment.id} className="bg-white rounded-lg shadow-sm p-4">
                <div className="flex items-center text-sm text-gray-500 mb-2">
                  <span className="font-medium">{comment.author}</span>
                  <span className="mx-2">•</span>
                  <span>{formatDistanceToNow(new Date(comment.created_utc))} ago</span>
                </div>
                <div className="prose text-gray-700">
                  {comment.body.split('\n').map((paragraph, i) => (
                    paragraph ? <p key={i} className="mb-2">{paragraph}</p> : <br key={i} />
                  ))}
                </div>
              </div>
            ))}
          </div>
        </section>
      )}
    </div>
  );
}
```

### Step 22: Implement API Routes with Proper Error Handling

```typescript
// app/api/rag/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { ragService } from '@/services/ragService';
import { supabaseAdmin } from '@/lib/supabase';
import { cacheService } from '@/services/cacheService';
import { PerformanceMonitor, withPerformanceTracking } from '@/utils/performance';
import { logger } from '@/utils/logger';

async function handler(request: NextRequest) {
  const monitor = new PerformanceMonitor();
  
  try {
    const { query } = await request.json();
    
    if (!query || typeof query !== 'string') {
      return NextResponse.json(
        { error: 'Valid query string is required' },
        { status: 400 }
      );
    }
    
    // First check Redis cache (faster than database)
    monitor.markStart('cache_check');
    const cachedResponse = await cacheService.getResponse(query);
    monitor.markEnd('cache_check');
    
    if (cachedResponse) {
      return NextResponse.json(cachedResponse);
    }
    
    // Then check database cache
    monitor.markStart('db_cache_check');
    const { data: dbCachedResponse } = await supabaseAdmin
      .from('query_cache')
      .select('response')
      .eq('query', query.toLowerCase().trim())
      .maybeSingle();
    monitor.markEnd('db_cache_check');
      
    // If we have a cached response, return it and also store in Redis
    if (dbCachedResponse) {
      await cacheService.storeResponse(query, dbCachedResponse.response);
      return NextResponse.json(dbCachedResponse.response);
    }
    
    // Generate new response
    monitor.markStart('rag_generation');
    const response = await ragService.generateResponse(query);
    monitor.markEnd('rag_generation');
    
    // Cache the response in both Redis and database
    await Promise.all([
      cacheService.storeResponse(query, response),
      supabaseAdmin
        .from('query_cache')
        .insert({
          query: query.toLowerCase().trim(),
          response
        })
    ]);
    
    // Log performance metrics
    monitor.logMetrics({ 
      query_length: query.length,
      has_locations: response.sources.some(s => s.title.includes('location')),
      source_count: response.sources.length
    });
    
    return NextResponse.json(response);
  } catch (error: any) {
    logger.error('RAG generation failed', { 
      error: error.message,
      stack: error.stack 
    });
    
    return NextResponse.json(
      { error: error.message || 'Failed to generate recommendations' },
      { status: 500 }
    );
  }
}

// Wrap the handler with performance tracking middleware
export const POST = withPerformanceTracking(handler);
```

### Step 23: Add Sitemap Generation for SEO

```typescript
// app/sitemap.ts
import { MetadataRoute } from 'next';
import { supabaseAdmin } from '@/lib/supabase';

export default async function sitemap(): Promise<MetadataRoute.Sitemap> {
  const baseUrl = process.env.NEXT_PUBLIC_BASE_URL || 'https://localguru.yourdomain.com';
  
  // Static routes
  const routes = [
    {
      url: `${baseUrl}/`,
      lastModified: new Date(),
      changeFrequency: 'daily' as const,
      priority: 1.0,
    },
  ];
  
  // Dynamic post routes - fetch top posts for SEO
  const { data: posts } = await supabaseAdmin
    .from('reddit_posts')
    .select('id, created_at')
    .order('score', { ascending: false })
    .limit(100);
    
  if (posts) {
    const postUrls = posts.map(post => ({
      url: `${baseUrl}/post/${post.id}`,
      lastModified: new Date(post.created_at),
      changeFrequency: 'weekly' as const,
      priority: 0.7,
    }));
    
    return [...routes, ...postUrls];
  }
  
  return routes;
}
```

## Advantages of Server-Side Rendering

1. **Improved SEO**: Search engines can index the fully rendered content
2. **Better Performance**: Faster First Contentful Paint (FCP) and Time To Interactive (TTI)
3. **Reduced Client-Side JS**: Most components run on the server, reducing bundle size
4. **Progressive Enhancement**: Basic functionality works even with JS disabled
5. **Data Security**: API keys and sensitive operations remain on the server
6. **Simplified State Management**: Data fetching happens on the server, reducing client-side state complexity

This enhanced implementation with Next.js 14 App Router maintains a clean separation between server and client components, follows the "server-first" approach, and provides a responsive, accessible user experience with proper loading and error states.
